"""
Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu CSE-CIC-IDS2018:
- ƒê·ªçc t·∫•t c·∫£ file CSV trong data/raw
- Chu·∫©n h√≥a t√™n c·ªôt
- Lo·∫°i b·ªè c·ªôt kh√¥ng c·∫ßn
- Chu·∫©n h√≥a label (0: Benign, 1: Attack)
- Lo·∫°i b·ªè NaN, gi√° tr·ªã v√¥ c·ª±c, tr√πng l·∫∑p
- C√¢n b·∫±ng d·ªØ li·ªáu (n·∫øu c·∫ßn)
- √âp ki·ªÉu an to√†n tr∆∞·ªõc khi l∆∞u
- L∆∞u sang ƒë·ªãnh d·∫°ng Parquet ƒë·ªÉ train nhanh h∆°n
"""

import os
import numpy as np
import pandas as pd
from fastai.tabular.all import df_shrink
from fastcore.parallel import parallel

RAW_DATA_DIR = "data/raw"
PROCESSED_DATA_DIR = "data/processed"
os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)

col_name_consistency = {
    # ...gi·ªØ nguy√™n nh∆∞ b·∫°n ƒë√£ mapping...
    # (b·∫°n c√≥ th·ªÉ copy l·∫°i ph·∫ßn mapping c·ªôt ·ªü tr√™n)
}

drop_columns = [
    "Flow ID", 'Fwd Header Length.1',
    "Source IP", "Src IP", "Source Port", "Src Port",
    "Destination IP", "Dst IP", "Destination Port", "Dst Port",
    "Timestamp"
]

def normalize_label(label):
    """Chuy·ªÉn label v·ªÅ 0 (Benign) v√† 1 (Attack)"""
    if str(label).strip().lower() in ["benign", "benign\n", "0", "normal"]:
        return 0
    return 1

def process_csv(path):
    print(f"üìÇ ƒêang x·ª≠ l√Ω: {path}")
    df = pd.read_csv(path, sep=",", encoding="utf-8")
    df.columns = df.columns.str.strip()
    df.rename(columns=col_name_consistency, inplace=True)
    df.drop(columns=drop_columns, inplace=True, errors="ignore")

    # Chu·∫©n h√≥a label
    df['Label'] = df['Label'].replace({'BENIGN': 'Benign'})
    df['Label'] = df['Label'].apply(normalize_label)

    # √âp to√†n b·ªô c√°c c·ªôt (tr·ª´ Label) v·ªÅ float n·∫øu c√≥ th·ªÉ, n·∫øu kh√¥ng th√¨ v·ªÅ string
    for col in df.columns:
        if col != 'Label':
            try:
                df[col] = pd.to_numeric(df[col], errors='raise')
            except Exception:
                df[col] = df[col].astype(str)

    # X·ª≠ l√Ω c·ªôt Protocol: gi·ªØ d·∫°ng string ho·∫∑c int an to√†n
    if 'Protocol' in df.columns:
        try:
            df['Protocol'] = pd.to_numeric(df['Protocol'], errors='raise').astype(np.int32)
        except Exception:
            df['Protocol'] = df['Protocol'].astype(str)

    # Lo·∫°i b·ªè gi√° tr·ªã v√¥ c·ª±c v√† NaN
    df.replace([np.inf, -np.inf], np.nan, inplace=True)
    df.dropna(inplace=True)

    # X√≥a tr√πng l·∫∑p
    df.drop_duplicates(inplace=True)
    df.reset_index(drop=True, inplace=True)

    # Thu g·ªçn dtype
    df = df_shrink(df)

    # L∆∞u parquet
    filename = os.path.basename(path).replace(".csv", ".parquet")
    save_path = os.path.join(PROCESSED_DATA_DIR, filename)
    df.to_parquet(save_path, index=False, engine="pyarrow")
    print(f"‚úÖ L∆∞u xong: {save_path}")
    return save_path

if __name__ == "__main__":
    csv_files = [
        os.path.join(RAW_DATA_DIR, f)
        for f in os.listdir(RAW_DATA_DIR)
        if f.endswith(".csv")
    ]

    if not csv_files:
        print("‚ö† Kh√¥ng t√¨m th·∫•y file CSV trong th∆∞ m·ª•c data/raw")
    else:
        processed_paths = parallel(process_csv, csv_files, progress=True)
        # G·ªôp l·∫°i th√†nh 1 file parquet l·ªõn v√† c√¢n b·∫±ng d·ªØ li·ªáu n·∫øu c·∫ßn
        dfs = [pd.read_parquet(p) for p in processed_paths]
        df_all = pd.concat(dfs, ignore_index=True)
        # C√¢n b·∫±ng d·ªØ li·ªáu (optional, n·∫øu d·ªØ li·ªáu l·ªách nhi·ªÅu)
        min_count = min(df_all["Label"].value_counts().values)
        df_balanced = pd.concat([
            df_all[df_all["Label"] == 0].sample(min_count, random_state=42),
            df_all[df_all["Label"] == 1].sample(min_count, random_state=42)
        ], ignore_index=True)
        df_balanced = df_shrink(df_balanced)
        final_path = os.path.join(PROCESSED_DATA_DIR, "cic2018_processed.parquet")
        df_balanced.to_parquet(final_path, index=False)
        print(f"üéØ ƒê√£ l∆∞u file t·ªïng h·ª£p c√¢n b·∫±ng: {final_path}")